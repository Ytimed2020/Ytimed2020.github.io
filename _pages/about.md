---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

[//]: # ({% if site.google_scholar_stats_use_cdn %})

[//]: # ({% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %})

[//]: # ({% else %})

[//]: # ({% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %})

[//]: # ({% endif %})

[//]: # ({% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %})

<span class='anchor' id='about-me'></span>

Have a happy day! ğŸ˜Š

I am Yudong Yang, an undergraduate student currently working as a Research Assistant at the Shenzhen Institutes of Advanced Technology (SIAT), Chinese Academy of Sciences (CAS), under the supervision of Lan Wang, Nan Yan, and Rongfeng Su.

Prior to joining SIAT, I gained valuable experience through internships at leading companies and institutions, including Sensetime, Xbotpark Robotics, and as a visiting student at SIAT.

My research interests lie in speech AI, speech LLM, and multi-modal learning.



[//]: # ()
[//]: # (# ğŸ“ Publications )

[//]: # (<div class='paper-box-text' markdown="1">)

[//]: # ([Deep Residual Learning for Image Recognition]&#40;https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf&#41;)

[//]: # (**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun)

[//]: # (</div>)



# ğŸ”¥ News

- **Oct 2025**: One paper accepted to **Information Fusion**.
- **Oct 2025**: One paper accepted to **Knowledge-Based Systems**.
- **May 2025**: Two papers accepted to **INTERSPEECH 2025**.
- **Mar 2025**: One paper accepted to **Scientific Data (Nature)** â€” ğŸš€ Released the **AUSpeech**!
- **Feb 2025**: One paper accepted to **IEEE/ACM Transactions on Audio, Speech, and Language Processing**.
- **Nov 2024**: Won **1st place** at the **SLT 2024 Workshop** â€” paper accepted to **INTERSPEECH 2025**.
- **Sep 2024**: Two papers accepted to **ISCSLP 2024** â€” ğŸš€ Released the **MSDM and challenge**!
- **Aug 2024**: One paper accepted to **ICSR 2024** â€” ğŸ† **Winner of the Best Paper Award**.
- **Jun 2024**: One paper accepted to **INTERSPEECH 2024**.
- **Dec 2023**: One paper accepted to **ICASSP 2024**.

---

# ğŸ† Honors & Awards

- **2024** â€“ ğŸ¥‡ **1st Place**, SLT 2024 Workshop
- **2024** â€“ ğŸ† **Best Paper Award**, ICSR 2024
- **2024** â€“ â­ **Faculty of Excellent Students Award**, SIAT
- **2023** â€“ ğŸŒŸ **Excellent Award**, MICCAI 2024 Workshop
- **2022** â€“ ğŸ§  **Dean Innovation Award (Team)**, Sensetime
- **2022** â€“ ğŸ… **Excellent Students Award / Best Team Award**, Xbotpark
- **2021** â€“ ğŸ¥‡ **Gold Student Award**, WAVE SUMMIT+ Deep Learning Developer Conference (Award presented by Haifeng Wang, Baidu CTO)

---

# ğŸ’¬ Academic Activities

- **Open Source Contributions**:  
  Contributed to [Open-Sora-Plan](https://github.com/PKU-YuanGroup/Open-Sora-Plan) (12K+ â­) and [PaddleDetection](https://github.com/PaddlePaddle/PaddleDetection) (13K+ â­), among others.

- **Reviewer**:
    - *IEEE Journal of Biomedical and Health Informatics (JBHI)*
    - *International Joint Conference on Neural Networks (IJCNN) 2025*
    - *Association for the Advancement of Artificial Intelligence (AAAI) 2025*

- **Special Session Committee**:
    - *ISCSLP 2024*

- **Presenter**:
    - *CAAI ICASSP Pre-talk Forum*

- **Leadership & Roles**:
    - **Area Chair**, Baidu PaddlePaddle "é¢†èˆªå›¢" Developer Committee (2022â€“2023)
    - **Student Leader**, NUC-AI LAB (2022â€“2023)

---

# ğŸ’» Competitions & Others

- ğŸ¥‡ **First Prize**, China Artificial Intelligence and Robotics Competition
- ğŸ¥‡ **First Prize**, Computer Application Competition in Five Provinces of North China & Hong Kong, Macao, Taiwan
- ğŸ¥ˆ **Second Prize**, China Collegiate Student Service Outsourcing Innovation and Entrepreneurship Competition
- ğŸ¥ˆ **Second Prize**, China Collegiate Computing Competition
- ğŸ¥‰ **Third Prize**, China Software Cup

---

ğŸ“« Feel free to reach out for collaboration or a chat!